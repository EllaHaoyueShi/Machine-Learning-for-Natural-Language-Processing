{
  "cells": [
    {
      "metadata": {
        "id": "f90871a1e738116"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab Report: NER using Transformer-Based Models\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Named Entity Recognition (NER) is a fundamental task in Natural Language Processing (NLP) that involves identifying and classifying entities within text into predefined categories such as names of persons, organizations, locations, dates, and more. Accurate NER is crucial for various applications, including information extraction, question answering, and machine translation.\n",
        "\n",
        "This exercise aims to implement an NER system using transformer-based neural architectures, specifically leveraging HuggingFace's `Camembert` model for the French language. By fine-tuning pre-trained transformer models on a specific NER task, we explore the effectiveness of contextualized embeddings in understanding and classifying entities within textual data.\n"
      ],
      "id": "f90871a1e738116"
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-11-14T13:09:17.929132Z",
          "start_time": "2024-11-14T13:09:17.927469Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "2e84894f-d24d-49f0-efbd-0fd25dd0d9a3"
      },
      "source": [
        "# # Installation\n",
        "!pip install polyglot\n",
        "!pip install pyicu\n",
        "!pip install datasets==2.21.0\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install seqeval\n",
        "!pip install pycld2\n",
        "!pip install morfessor\n",
        "!pip install evaluate\n",
        "!pip install accelerate -U\n",
        "!pip install seqeval"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting polyglot\n",
            "  Downloading polyglot-16.7.4.tar.gz (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52562 sha256=4eb91588643f67cdbdd63a10f48b79c547e47b0e4646029f413b3ef7485e3e48\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/92/4a/b172589446ba537db3bdb9a1f2204f27fe71217981c14ac368\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n",
            "Collecting pyicu\n",
            "  Downloading PyICU-2.14.tar.gz (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.9/263.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyicu\n",
            "  Building wheel for pyicu (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyicu: filename=PyICU-2.14-cp310-cp310-linux_x86_64.whl size=1809842 sha256=6911b32bc249d0815acc2e4be0da14dd644a811f1e4926247ef0ab14adb63d3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/6e/76/17c73021179c06c29d9b108896b9248da0de4f2af93f63d405\n",
            "Successfully built pyicu\n",
            "Installing collected packages: pyicu\n",
            "Successfully installed pyicu-2.14\n",
            "Collecting datasets==2.21.0\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.21.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (4.66.6)\n",
            "Collecting xxhash (from datasets==2.21.0)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.21.0)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==2.21.0)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.21.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.21.0) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.21.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.21.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.21.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.21.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.21.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.21.0) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.21.0) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.21.0) (0.2.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 fsspec-2024.6.1 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=760e530980f3a131cb9a2f519c0c19331efcf4a8005501d189adff62d916a7b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Collecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp310-cp310-linux_x86_64.whl size=9904068 sha256=94703a56cf6b2b2ef85bb0a791d628200a5622d45ab12634ca565c019f62b3dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/81/31/240c89c845e008a93d98542325270007de595bfd356eb0b06c\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n",
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: morfessor\n",
            "Successfully installed morfessor-2.0.6\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:09:18.668701Z",
          "start_time": "2024-11-14T13:09:18.667235Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "77ebaa4f3534f77e",
        "outputId": "d609c242-0cb5-45cf-d9de-ff0741a543b5"
      },
      "cell_type": "code",
      "source": [
        "# Download hf models and dataset\n",
        "!huggingface-cli download --repo-type dataset rmyeid/polyglot_ner --local-dir polyglot_ner --force-download\n",
        "!huggingface-cli download --resume-download almanach/camembert-base --local-dir camembert-base"
      ],
      "id": "77ebaa4f3534f77e",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 3 files:   0% 0/3 [00:00<?, ?it/s]Downloading 'README.md' to 'polyglot_ner/.cache/huggingface/download/README.md.a7835e2499e2197d24e981d9ce7c1d6040bd8aee.incomplete'\n",
            "Downloading 'polyglot_ner.py' to 'polyglot_ner/.cache/huggingface/download/polyglot_ner.py.b125dfd404cc5328a07b89fe66c5d0642efddc76.incomplete'\n",
            "Downloading '.gitattributes' to 'polyglot_ner/.cache/huggingface/download/.gitattributes.957b2579c6ef20995a09efd9a17f8fd90606f5ed.incomplete'\n",
            "\n",
            "polyglot_ner.py: 100% 6.01k/6.01k [00:00<00:00, 27.4MB/s]\n",
            "Download complete. Moving file to polyglot_ner/polyglot_ner.py\n",
            "\n",
            ".gitattributes: 100% 1.17k/1.17k [00:00<00:00, 11.5MB/s]\n",
            "Download complete. Moving file to polyglot_ner/.gitattributes\n",
            "Fetching 3 files:  33% 1/3 [00:00<00:01,  1.98it/s]\n",
            "README.md: 100% 22.5k/22.5k [00:00<00:00, 57.6MB/s]\n",
            "Download complete. Moving file to polyglot_ner/README.md\n",
            "Fetching 3 files: 100% 3/3 [00:00<00:00,  5.63it/s]\n",
            "/content/polyglot_ner\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Fetching 9 files:   0% 0/9 [00:00<?, ?it/s]Downloading 'tf_model.h5' to 'camembert-base/.cache/huggingface/download/tf_model.h5.1a7be48987fe8c135cb985e9b0f07cc5c14d3b1b934b7fd16f4844a3b3e884a9.incomplete'\n",
            "Downloading 'sentencepiece.bpe.model' to 'camembert-base/.cache/huggingface/download/sentencepiece.bpe.model.e84a8997bb03a815aab434b82f5d99e2c35fafb8.incomplete'\n",
            "Downloading 'tokenizer.json' to 'camembert-base/.cache/huggingface/download/tokenizer.json.37cac90e9f6f97be82ab09861847572d4a85390d.incomplete'\n",
            "Downloading 'model.safetensors' to 'camembert-base/.cache/huggingface/download/model.safetensors.486643fdcac936afc551aa4b0fedcd9f61c5f71f42b8333e07c709f38043475d.incomplete'\n",
            "Downloading 'config.json' to 'camembert-base/.cache/huggingface/download/config.json.ea407689031fd146da8a53085337be8934d761c5.incomplete'\n",
            "Downloading 'README.md' to 'camembert-base/.cache/huggingface/download/README.md.3cc7c87f3c4ce3e235eafbc24c2163e6b3e157c6.incomplete'\n",
            "Downloading 'pytorch_model.bin' to 'camembert-base/.cache/huggingface/download/pytorch_model.bin.54ca0c5f4daf6885f7b07df460624de6120fe5cf964f9b082a4874be6249f5f5.incomplete'\n",
            "Downloading '.gitattributes' to 'camembert-base/.cache/huggingface/download/.gitattributes.9a0990c5c0e00e26cc5ca4ba5c1c3ad533de7018.incomplete'\n",
            "\n",
            "sentencepiece.bpe.model:   0% 0.00/811k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "tokenizer.json:   0% 0.00/1.40M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/445M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 508/508 [00:00<00:00, 2.22MB/s]\n",
            "Download complete. Moving file to camembert-base/config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "README.md: 100% 5.25k/5.25k [00:00<00:00, 24.6MB/s]\n",
            "Download complete. Moving file to camembert-base/README.md\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   0% 0.00/445M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   5% 21.0M/445M [00:00<00:02, 196MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ".gitattributes: 100% 399/399 [00:00<00:00, 2.11MB/s]\n",
            "Download complete. Moving file to camembert-base/.gitattributes\n",
            "Fetching 9 files:  11% 1/9 [00:00<00:05,  1.55it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   0% 0.00/543M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  12% 52.4M/445M [00:00<00:01, 231MB/s]\u001b[A\u001b[A\u001b[ADownloading 'tokenizer_config.json' to 'camembert-base/.cache/huggingface/download/tokenizer_config.json.34ddbd64a4cd3f2d9d8a9120d3662d0bf91baead.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 83.9M/445M [00:00<00:01, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 131kB/s]\n",
            "Download complete. Moving file to camembert-base/tokenizer_config.json\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 115M/445M [00:00<00:01, 237MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   2% 10.5M/445M [00:00<00:19, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   2% 10.5M/543M [00:00<00:23, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tokenizer.json: 100% 1.40M/1.40M [00:00<00:00, 2.10MB/s]\n",
            "Download complete. Moving file to camembert-base/tokenizer.json\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  33% 147M/445M [00:00<00:01, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  40% 178M/445M [00:00<00:01, 230MB/s]\u001b[A\u001b[A\u001b[A\n",
            "sentencepiece.bpe.model: 100% 811k/811k [00:00<00:00, 941kB/s]\n",
            "Download complete. Moving file to camembert-base/sentencepiece.bpe.model\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  47% 210M/445M [00:00<00:00, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  54% 241M/445M [00:01<00:00, 240MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   4% 21.0M/543M [00:00<00:22, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   5% 21.0M/445M [00:01<00:22, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  61% 273M/445M [00:01<00:00, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  68% 304M/445M [00:01<00:00, 205MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   6% 31.5M/543M [00:01<00:21, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  75% 336M/445M [00:01<00:00, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  82% 367M/445M [00:01<00:00, 216MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   7% 31.5M/445M [00:01<00:23, 17.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  90% 398M/445M [00:01<00:00, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   8% 41.9M/543M [00:01<00:21, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors: 100% 445M/445M [00:02<00:00, 213MB/s]\n",
            "Download complete. Moving file to camembert-base/model.safetensors\n",
            "Fetching 9 files:  44% 4/9 [00:02<00:03,  1.53it/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   9% 41.9M/445M [00:02<00:19, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  10% 52.4M/543M [00:02<00:20, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  12% 52.4M/445M [00:02<00:20, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  12% 62.9M/543M [00:02<00:20, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  14% 62.9M/445M [00:03<00:18, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  14% 73.4M/543M [00:03<00:19, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  16% 73.4M/445M [00:03<00:17, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  15% 83.9M/543M [00:03<00:19, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  17% 94.4M/543M [00:03<00:18, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  19% 83.9M/445M [00:04<00:18, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  19% 105M/543M [00:04<00:18, 23.8MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  21% 94.4M/445M [00:04<00:16, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  21% 115M/543M [00:04<00:17, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  24% 105M/445M [00:05<00:15, 22.1MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  23% 126M/543M [00:05<00:17, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  26% 115M/445M [00:05<00:14, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  25% 136M/543M [00:05<00:17, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  28% 126M/445M [00:05<00:13, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  27% 147M/543M [00:06<00:16, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  31% 136M/445M [00:06<00:13, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  29% 157M/543M [00:06<00:16, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  33% 147M/445M [00:06<00:12, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  31% 168M/543M [00:07<00:15, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  35% 157M/445M [00:07<00:11, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  33% 178M/543M [00:07<00:15, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  38% 168M/445M [00:07<00:11, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  35% 189M/543M [00:07<00:14, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  40% 178M/445M [00:08<00:10, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  42% 189M/445M [00:08<00:10, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  37% 199M/543M [00:08<00:14, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  39% 210M/543M [00:08<00:14, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  45% 199M/445M [00:08<00:10, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  41% 220M/543M [00:09<00:13, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  47% 210M/445M [00:09<00:09, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  49% 220M/445M [00:09<00:09, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  42% 231M/543M [00:09<00:13, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  52% 231M/445M [00:10<00:08, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  44% 241M/543M [00:10<00:12, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  54% 241M/445M [00:10<00:08, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  46% 252M/543M [00:10<00:12, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  57% 252M/445M [00:11<00:07, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  48% 262M/543M [00:11<00:11, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  50% 273M/543M [00:11<00:11, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  59% 262M/445M [00:11<00:07, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  52% 283M/543M [00:11<00:10, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  61% 273M/445M [00:12<00:07, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  54% 294M/543M [00:12<00:10, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  64% 283M/445M [00:12<00:06, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  66% 294M/445M [00:12<00:06, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  56% 304M/543M [00:12<00:10, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  68% 304M/445M [00:13<00:05, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  58% 315M/543M [00:13<00:09, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  71% 315M/445M [00:13<00:05, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  60% 325M/543M [00:13<00:09, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  73% 325M/445M [00:14<00:04, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  62% 336M/543M [00:14<00:08, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  75% 336M/445M [00:14<00:04, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  64% 346M/543M [00:14<00:08, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  78% 346M/445M [00:15<00:04, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  66% 357M/543M [00:15<00:07, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  80% 357M/445M [00:15<00:03, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  68% 367M/543M [00:15<00:07, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  82% 367M/445M [00:15<00:03, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  70% 377M/543M [00:15<00:06, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  85% 377M/445M [00:16<00:02, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  71% 388M/543M [00:16<00:06, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  87% 388M/445M [00:16<00:02, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  73% 398M/543M [00:16<00:06, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  90% 398M/445M [00:17<00:01, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  75% 409M/543M [00:17<00:05, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  92% 409M/445M [00:17<00:01, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  77% 419M/543M [00:17<00:05, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  94% 419M/445M [00:17<00:01, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  79% 430M/543M [00:18<00:04, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  97% 430M/445M [00:18<00:00, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  81% 440M/543M [00:18<00:04, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  99% 440M/445M [00:18<00:00, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin: 100% 445M/445M [00:19<00:00, 23.4MB/s]\n",
            "Download complete. Moving file to camembert-base/pytorch_model.bin\n",
            "Fetching 9 files:  56% 5/9 [00:19<00:20,  5.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  83% 451M/543M [00:18<00:03, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  85% 461M/543M [00:19<00:03, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  87% 472M/543M [00:19<00:02, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  89% 482M/543M [00:20<00:02, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  91% 493M/543M [00:20<00:02, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  93% 503M/543M [00:21<00:01, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  95% 514M/543M [00:21<00:01, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  97% 524M/543M [00:22<00:00, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  99% 535M/543M [00:22<00:00, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5: 100% 543M/543M [00:22<00:00, 23.6MB/s]\n",
            "Download complete. Moving file to camembert-base/tf_model.h5\n",
            "Fetching 9 files: 100% 9/9 [00:23<00:00,  2.63s/it]\n",
            "/content/camembert-base\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:06.832644Z",
          "start_time": "2024-11-14T13:29:05.168590Z"
        },
        "id": "79e044283a7507"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import (\n",
        "    CamembertTokenizerFast,\n",
        "    CamembertForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from collections import Counter\n",
        "from datasets import Dataset, DatasetDict\n"
      ],
      "id": "79e044283a7507",
      "outputs": [],
      "execution_count": 66
    },
    {
      "metadata": {
        "id": "b67af294713047e9"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Explore the Dataset\n"
      ],
      "id": "b67af294713047e9"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:07.474289Z",
          "start_time": "2024-11-14T13:29:07.431610Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d971d2b748780cbb",
        "outputId": "998530ca-f4af-42a3-bc06-f4305a0565e5"
      },
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('./polyglot_ner/polyglot_ner.py', 'fr')\n",
        "dataset\n"
      ],
      "id": "d971d2b748780cbb",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'lang', 'words', 'ner'],\n",
              "        num_rows: 418411\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "execution_count": 73
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:07.665255Z",
          "start_time": "2024-11-14T13:29:07.663290Z"
        },
        "id": "30de8972d74d44fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8154c7-31df-40e6-b775-65c512a882ca"
      },
      "cell_type": "code",
      "source": [
        "# total number of sentences in the dataset\n",
        "total_sentences = len(dataset['train'])\n",
        "print(f\"Total sentences in the dataset: {total_sentences}\")"
      ],
      "id": "30de8972d74d44fe",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences in the dataset: 418411\n"
          ]
        }
      ],
      "execution_count": 74
    },
    {
      "metadata": {
        "id": "1d6611b5a7eaaf89"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Data Preparation"
      ],
      "id": "1d6611b5a7eaaf89"
    },
    {
      "metadata": {
        "id": "7a6088747810d86c"
      },
      "cell_type": "markdown",
      "source": [
        "### Language Choice\n",
        "\n",
        "For this exercise, we selected **French** from the Polyglot-NER dataset. The selection criteria included:\n",
        "- **Non-English Language:** Ensuring the language is not English to explore NER capabilities in other linguistic contexts.\n",
        "- **Dataset Size:** The French subset contains over 7,000 sentences, meeting the minimum requirement for effective model training.\n",
        "- **Model Availability:** A pre-trained HuggingFace `Camembert` model is available for French, facilitating the fine-tuning process.\n",
        "\n",
        "### Dataset Details\n",
        "\n",
        "The Polyglot-NER dataset encompasses 40 languages, each annotated for named entities. For French (`'fr'`), the dataset comprises a diverse range of sentences with various entity types annotated in the IOB format. The IOB tagging scheme labels tokens as:\n",
        "- **B-** (Beginning): The first token of a named entity.\n",
        "- **I-** (Inside): Tokens inside a named entity.\n",
        "- **O-** (Outside): Tokens outside any named entity.\n",
        "\n",
        "### Data Splitting\n",
        "\n",
        "To evaluate the model's performance under different training scenarios, the dataset was divided as follows:\n",
        "- **Training Set 1:** 1,000 sentences for initial fine-tuning.\n",
        "- **Training Set 2:** 3,000 sentences for extended fine-tuning.\n",
        "- **Evaluation Set:** 2,000 sentences used to assess model performance.\n",
        "\n",
        "This stratified splitting ensures that each subset maintains a representative distribution of entity types, enabling robust evaluation of the models.\n"
      ],
      "id": "7a6088747810d86c"
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_iob_format(data):\n",
        "    iob_ner = []\n",
        "    prev_tag = \"O\"\n",
        "\n",
        "    for tag in data['ner']:\n",
        "        if tag.startswith(\"B-\") or tag.startswith(\"I-\") or tag == \"O\":\n",
        "            iob_ner.append(tag)\n",
        "        elif tag == \"O\":\n",
        "            iob_ner.append(\"O\")\n",
        "        elif tag != prev_tag:\n",
        "            iob_ner.append(f\"B-{tag}\")\n",
        "        else:\n",
        "            iob_ner.append(f\"I-{tag}\")\n",
        "        prev_tag = tag\n",
        "    data['ner'] = iob_ner\n",
        "    return data\n",
        "def convert_dataset_to_iob(dataset):\n",
        "    converted_dataset = []\n",
        "    for data in dataset:\n",
        "        converted_dataset.append(convert_to_iob_format(data))\n",
        "    return converted_dataset"
      ],
      "metadata": {
        "id": "UOPQjomM2r4u"
      },
      "id": "UOPQjomM2r4u",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'] = convert_dataset_to_iob(dataset['train'])"
      ],
      "metadata": {
        "id": "_DsowT8g2vXU"
      },
      "id": "_DsowT8g2vXU",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_list(dataset['train'])\n",
        "})"
      ],
      "metadata": {
        "id": "OEikq9Hc5QB6"
      },
      "id": "OEikq9Hc5QB6",
      "execution_count": 81,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:08.045994Z",
          "start_time": "2024-11-14T13:29:08.041088Z"
        },
        "id": "839c24535b4e6782",
        "outputId": "caf11b86-4592-47eb-a87d-9b18fcfaeb16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(seed=42)\n",
        "dataset"
      ],
      "id": "839c24535b4e6782",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'lang', 'words', 'ner'],\n",
              "        num_rows: 416411\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "execution_count": 82
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:08.251563Z",
          "start_time": "2024-11-14T13:29:08.246861Z"
        },
        "id": "a0e972e62621036d",
        "outputId": "49bc3392-f027-4d82-9e1c-3799160c4a0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluation set: 2,000 sentences\n",
        "eval_size = 2000\n",
        "\n",
        "# Split the dataset into training and evaluation\n",
        "dataset = dataset['train'].train_test_split(test_size=eval_size, seed=42)\n",
        "dataset['eval'] = dataset.pop('test')\n",
        "\n",
        "dataset"
      ],
      "id": "a0e972e62621036d",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'lang', 'words', 'ner'],\n",
              "        num_rows: 414411\n",
              "    })\n",
              "    eval: Dataset({\n",
              "        features: ['id', 'lang', 'words', 'ner'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "execution_count": 83
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:08.750088Z",
          "start_time": "2024-11-14T13:29:08.745761Z"
        },
        "id": "fb2f7031dacbaa96",
        "outputId": "38b2616e-c8cb-461d-f49f-d47718ad3da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Training subset\n",
        "\n",
        "# Training set 1: 1,000 sentences\n",
        "train_small = dataset['train'].select(range(1000))\n",
        "\n",
        "# Training set 2: 3,000 sentences\n",
        "train_medium = dataset['train'].select(range(3000))\n",
        "\n",
        "# Evaluation set\n",
        "eval_dataset = dataset['eval']\n",
        "\n",
        "train_small, train_medium, eval_dataset"
      ],
      "id": "fb2f7031dacbaa96",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['id', 'lang', 'words', 'ner'],\n",
              "     num_rows: 1000\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['id', 'lang', 'words', 'ner'],\n",
              "     num_rows: 3000\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['id', 'lang', 'words', 'ner'],\n",
              "     num_rows: 2000\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "execution_count": 84
    },
    {
      "metadata": {
        "id": "c99d346a94a57fd8"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Tokenization and Label Alignment"
      ],
      "id": "c99d346a94a57fd8"
    },
    {
      "metadata": {
        "id": "512cd3588c58f1ac"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Selection and Tokenization\n",
        "\n",
        "### Model Choice\n",
        "\n",
        "We utilized the **Camembert** model (`CamembertForTokenClassification`) from HuggingFace, specifically designed for the French language. Camembert is a robust transformer-based model that builds upon the RoBERTa architecture, offering enhanced performance for French NLP tasks. Its pre-trained nature allows for effective fine-tuning on specific tasks like NER, leveraging the rich contextual embeddings it provides.\n",
        "\n",
        "### Tokenizer Alignment\n",
        "\n",
        "Tokenization is a critical preprocessing step that converts raw text into tokens compatible with the transformer model. We employed `CamembertTokenizerFast` to ensure consistency with the Camembert model.\n",
        "\n",
        "**Key Steps in Tokenization and Label Alignment:**\n",
        "1. **Tokenization:** The tokenizer splits sentences into subword tokens, handling cases where words are broken down into smaller units.\n",
        "2. **Label Alignment:** Since subword tokenization can split entities into multiple tokens, we align the original IOB labels with the tokenized outputs. This involves:\n",
        "   - Assigning the original label to the first sub-token of a word.\n",
        "   - Optionally labeling subsequent sub-tokens based on the `label_all_tokens` flag.\n",
        "   - Assigning a special label (`-100`) to padding and special tokens to exclude them from loss computation.\n",
        "\n",
        "Proper alignment ensures that the model accurately learns the association between tokens and their corresponding entity labels, even when words are split into sub-tokens.\n"
      ],
      "id": "512cd3588c58f1ac"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:09.823238Z",
          "start_time": "2024-11-14T13:29:09.781072Z"
        },
        "id": "a74cd064ddc6e1f4"
      },
      "cell_type": "code",
      "source": [
        "tokenizer = CamembertTokenizerFast.from_pretrained('./camembert-base')\n"
      ],
      "id": "a74cd064ddc6e1f4",
      "outputs": [],
      "execution_count": 11
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:15.866366Z",
          "start_time": "2024-11-14T13:29:10.530188Z"
        },
        "id": "afafa1dd3f7afe77",
        "outputId": "6b349fb5-200c-4f1b-bd9c-87ad2b1aaf40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a label mapping.\n",
        "# Collect all unique labels from the dataset\n",
        "label_counter = Counter()\n",
        "for split in ['train', 'eval']:\n",
        "    for labels in dataset[split]['ner']:\n",
        "        label_counter.update(labels)\n",
        "print(label_counter)\n",
        "\n",
        "label_list = list(label_counter.keys())\n",
        "label_list.sort()  # Sort labels for consistency\n",
        "print(f\"Labels: {label_list}\")\n",
        "\n",
        "# Create label to ID and ID to label mappings\n",
        "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
        "id_to_label = {i: label for label, i in label_to_id.items()}\n",
        "label_to_id, id_to_label"
      ],
      "id": "afafa1dd3f7afe77",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'O': 9383763, 'B-LOC': 181327, 'B-PER': 104383, 'I-PER': 83280, 'I-LOC': 76308, 'B-ORG': 63013, 'I-ORG': 61512})\n",
            "Labels: ['B-LOC', 'B-ORG', 'B-PER', 'I-LOC', 'I-ORG', 'I-PER', 'O']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'B-LOC': 0,\n",
              "  'B-ORG': 1,\n",
              "  'B-PER': 2,\n",
              "  'I-LOC': 3,\n",
              "  'I-ORG': 4,\n",
              "  'I-PER': 5,\n",
              "  'O': 6},\n",
              " {0: 'B-LOC',\n",
              "  1: 'B-ORG',\n",
              "  2: 'B-PER',\n",
              "  3: 'I-LOC',\n",
              "  4: 'I-ORG',\n",
              "  5: 'I-PER',\n",
              "  6: 'O'})"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "execution_count": 85
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:15.877106Z",
          "start_time": "2024-11-14T13:29:15.874961Z"
        },
        "id": "5cb4acff3c4515eb"
      },
      "cell_type": "code",
      "source": [
        "label_all_tokens = True  # Set to True to label all sub-tokens\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"words\"],\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to words\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                # Special token\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # Start of a new word\n",
        "                label_ids.append(label_to_id[label[word_idx]])\n",
        "            else:\n",
        "                # Same word or sub-token\n",
        "                if label_all_tokens:\n",
        "                    label_ids.append(label_to_id[label[word_idx]])\n",
        "                else:\n",
        "                    label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ],
      "id": "5cb4acff3c4515eb",
      "outputs": [],
      "execution_count": 86
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:16.134458Z",
          "start_time": "2024-11-14T13:29:15.924861Z"
        },
        "id": "61ad950cde332c4d",
        "outputId": "f71262ab-ad2e-40a1-94bd-7a242c03c2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "cdfd4f219e454a52990b5a15a2dcb9d4",
            "8475e788fdd74f168e65aecf8dca9925",
            "4e36587f8ffc4125aaff3007af2a8b8f",
            "51a955707c284a07a5d37be11bba3bdc",
            "0485ab78bfb5472fb3ab2a4adcfef13c",
            "47bafaffbb5846f2b96d83205808a8e2",
            "2ba9dcef40cd4a19a3d6b3ab665da8f3",
            "1708892423294453bc52190c5c17a81d",
            "b74f0339d9da422f9d82d5f53405b476",
            "94696ea690b14014b9278d46bac07de8",
            "e50f6eb55e0341aab7fe66431d433516",
            "bbccec2995914e1aa2be0674e17c5c11",
            "934df28ea11c476a81f4449987fedd2a",
            "196daee64ac54b83a801a71531488f99",
            "211104dd64c7431b883f16d1e18c6fc6",
            "0762ab2f2fb7451d8f95b3e38a2be93f",
            "b13ac3caf5fe4bd584597a8da6bc90e7",
            "ab729840215042c09e025cdcce3bab2d",
            "83cddabd157246828ed019f69feb5c75",
            "87dc283b21f34017bb519eb6448e00bf",
            "97e5c41ceaa04e2b85ef9f4c1dabad40",
            "c594f58a0285411b829c3b14f30dd744",
            "fdee57962ef744cfbd0a185a4e90401b",
            "35e4eac73c314c83aa97f20abce55aa2",
            "0be63cc5fc654514b5e65ded39abb1a9",
            "306c95e7b029431baa405308fb22507f",
            "9adb12205a9049d4b7ac5cc339cbdb23",
            "4cbcb6efd10d4af1b1121269690afa95",
            "459085a739d84b57851c6b39df04155c",
            "1e660034002a4b50a45567ec57552590",
            "8766fb01418848c3ac56fd92dc14a033",
            "d9d66f6982a048cab8be0d60811f831b",
            "cb0acbcf4f5547af98b30868a195b7cc"
          ]
        }
      },
      "cell_type": "code",
      "source": [
        "# Apply the function to the datasets\n",
        "train_small_tokenized = train_small.map(tokenize_and_align_labels, batched=True)\n",
        "train_medium_tokenized = train_medium.map(tokenize_and_align_labels, batched=True)\n",
        "eval_tokenized = eval_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "train_small_tokenized, train_medium_tokenized, eval_tokenized"
      ],
      "id": "61ad950cde332c4d",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdfd4f219e454a52990b5a15a2dcb9d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbccec2995914e1aa2be0674e17c5c11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdee57962ef744cfbd0a185a4e90401b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['id', 'lang', 'words', 'ner', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 1000\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['id', 'lang', 'words', 'ner', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 3000\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['id', 'lang', 'words', 'ner', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 2000\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "execution_count": 87
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:29:16.201831Z",
          "start_time": "2024-11-14T13:29:16.199683Z"
        },
        "id": "e23b01ca030292a3"
      },
      "cell_type": "code",
      "source": [
        "# Set the format for PyTorch\n",
        "\n",
        "train_small_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "train_medium_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "eval_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
      ],
      "id": "e23b01ca030292a3",
      "outputs": [],
      "execution_count": 88
    },
    {
      "metadata": {
        "id": "77526670fb7d3a27"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Define Evaluation Metrics"
      ],
      "id": "77526670fb7d3a27"
    },
    {
      "metadata": {
        "id": "7dae50d181a93496"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "To assess the performance of our NER models, we employed two key evaluation metrics:\n",
        "\n",
        "1. **F1-Micro Score:**\n",
        "   - **Definition:** The micro F1 score calculates metrics globally by counting the total true positives, false negatives, and false positives.\n",
        "   - **Relevance:** It provides a single performance measure that accounts for both precision and recall across all entity types, offering an overall effectiveness of the model.\n",
        "\n",
        "2. **F1-Macro Score:**\n",
        "   - **Definition:** The macro F1 score computes the F1 score independently for each entity type and then takes the average.\n",
        "   - **Relevance:** It treats all entity types equally, highlighting the model's performance on less frequent or smaller classes, thereby addressing class imbalance issues.\n",
        "\n",
        "**Implementation:**\n",
        "We utilized the `seqeval` library to compute these metrics. The evaluation process involved:\n",
        "- **Prediction Extraction:** Deriving the most probable label for each token using `np.argmax`.\n",
        "- **Label Filtering:** Ignoring special tokens and padding by assigning a label of `-100`.\n",
        "- **Metric Computation:** Calculating `f1_micro` and `f1_macro` based on the predicted and true labels.\n",
        "\n",
        "These metrics collectively provide a comprehensive understanding of the model's NER capabilities, balancing overall accuracy with performance across individual entity categories.\n"
      ],
      "id": "7dae50d181a93496"
    },
    {
      "cell_type": "code",
      "source": [
        "def process_labels(labels):\n",
        "    entity_labels = {label.split(\"-\")[-1] for label in labels if label != \"O\"}\n",
        "\n",
        "    entity_labels = sorted(entity_labels)\n",
        "\n",
        "    return entity_labels\n"
      ],
      "metadata": {
        "id": "ShyIWWuy_EI3"
      },
      "id": "ShyIWWuy_EI3",
      "execution_count": 99,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:31:01.994149Z",
          "start_time": "2024-11-14T13:29:18.085816Z"
        },
        "id": "4bd3023892f43080"
      },
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [id_to_label[pred] for (pred, label_id) in zip(prediction, label) if label_id != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id_to_label[label_id] for (pred, label_id) in zip(prediction, label) if label_id != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "    # Micro F1 score (overall)\n",
        "    f1_micro = results.get(\"overall_f1\", 0.0)\n",
        "\n",
        "    # Define entity labels (exclude 'O')label_list\n",
        "    entity_labels = process_labels(label_list)\n",
        "    # Per-label F1 scores\n",
        "    per_label_f1 = []\n",
        "    for label in entity_labels:\n",
        "        if label in results:\n",
        "            label_f1 = results[label].get('f1', 0.0)\n",
        "            per_label_f1.append(label_f1)\n",
        "        else:\n",
        "            print(f\"Label '{label}' not found in results. Assigning 0.\")\n",
        "            per_label_f1.append(0.0)\n",
        "\n",
        "    # Compute macro F1 by averaging valid F1 scores\n",
        "    if per_label_f1:\n",
        "        f1_macro = np.mean(per_label_f1)\n",
        "    else:\n",
        "        f1_macro = 0.0\n",
        "    return {\n",
        "        \"f1_micro\": f1_micro,\n",
        "        \"f1_macro\": f1_macro,\n",
        "    }\n"
      ],
      "id": "4bd3023892f43080",
      "outputs": [],
      "execution_count": 100
    },
    {
      "metadata": {
        "id": "4c53b49f9ed2a644"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Model Training and Evaluation\n",
        "## Training Process\n",
        "\n",
        "### Training Configurations\n",
        "\n",
        "We fine-tuned three distinct models to explore the impact of training data size and model parameters on NER performance:\n",
        "\n",
        "1. **Model 1:** Fine-tuned with **1,000 sentences**.\n",
        "2. **Model 2:** Fine-tuned with **3,000 sentences**.\n",
        "3. **Model 3:** Fine-tuned with **3,000 sentences** and **frozen embeddings**.\n",
        "\n",
        "**Training Arguments:**\n",
        "- **Output Directory:** Specifies where to save model checkpoints and logs.\n",
        "- **Number of Epochs:** Set to 10 to allow sufficient training iterations.\n",
        "- **Batch Size:** A per-device batch size of 8 balances computational efficiency with memory constraints.\n",
        "- **Warmup Steps:** 500 steps to gradually increase the learning rate, aiding in stable training.\n",
        "- **Weight Decay:** 0.01 to prevent overfitting by penalizing large weights.\n",
        "- **Logging:** Configured to log training progress every 10 steps.\n",
        "- **Evaluation Strategy:** Evaluates the model at the end of each epoch to monitor performance.\n",
        "\n",
        "### Fine-Tuning Strategies\n",
        "\n",
        "1. **Model 1 (1,000 Sentences):**\n",
        "   - Utilizes a smaller training dataset to assess the model's ability to learn from limited data.\n",
        "   \n",
        "2. **Model 2 (3,000 Sentences):**\n",
        "   - Expands the training dataset to evaluate the effect of increased data on model performance.\n",
        "   \n",
        "3. **Model 3 (3,000 Sentences with Frozen Embeddings):**\n",
        "   - Freezes the embedding layers (`model.roberta.embeddings.parameters()`), restricting the model from updating these parameters during training.\n",
        "   - This approach tests whether retaining pre-trained embeddings without further adjustment impacts NER accuracy.\n",
        "\n",
        "### Resource Management\n",
        "\n",
        "Given the computational constraints, especially on platforms like Google Colab, we ensured efficient memory usage by:\n",
        "- Loading and fine-tuning one model at a time.\n",
        "- Deleting models from memory post-training using `del model` and `del trainer`.\n",
        "- Clearing CUDA cache with `torch.cuda.empty_cache()` to free GPU memory before loading the next model.\n",
        "\n",
        "### First Model"
      ],
      "id": "4c53b49f9ed2a644"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:34:28.308320Z",
          "start_time": "2024-11-14T13:34:28.286750Z"
        },
        "id": "c326fe9213b0cb3e",
        "outputId": "46ec0125-6f89-4d7f-be49-72f06f3c96f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# First Model: Fine-tuned with 1,000 sentences\n",
        "# Initialize the model\n",
        "num_labels = len(label_list)\n",
        "model = CamembertForTokenClassification.from_pretrained('./camembert-base',\n",
        "                                                        num_labels=num_labels,\n",
        "                                                        id2label=id_to_label,\n",
        "                                                        label2id=label_to_id)"
      ],
      "id": "c326fe9213b0cb3e",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at ./camembert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "execution_count": 90
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:34:29.326108Z",
          "start_time": "2024-11-14T13:34:28.618769Z"
        },
        "id": "d7851234319e0eb7",
        "outputId": "4da4afcb-57f4-4156-e9fc-fbe13dab8df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./training_show/results_first',          # Output directory\n",
        "    num_train_epochs=10,                    # Total number of training epochs\n",
        "    per_device_train_batch_size=8,         # Batch size per device during training\n",
        "    per_device_eval_batch_size=8,          # Batch size for evaluation\n",
        "    warmup_steps=500,                      # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,                     # Strength of weight decay\n",
        "    logging_dir='./training_show/logs_first',            # Directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",           # Evaluation at the end of each epoch\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_small_tokenized,\n",
        "    eval_dataset=eval_tokenized,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "id": "d7851234319e0eb7",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-101-82d65b360ffc>:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "execution_count": 101
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:36:45.618312Z",
          "start_time": "2024-11-14T13:34:29.566322Z"
        },
        "id": "25cedfe7e7dfa2de",
        "outputId": "b535d1a6-14d7-4b6e-9cfd-f7d491eea087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "id": "25cedfe7e7dfa2de",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 07:04, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Model Preparation Time</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>0.269762</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.532626</td>\n",
              "      <td>0.493102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.021300</td>\n",
              "      <td>0.278466</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.527909</td>\n",
              "      <td>0.489150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.015400</td>\n",
              "      <td>0.286154</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.523112</td>\n",
              "      <td>0.485000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>0.322412</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.515991</td>\n",
              "      <td>0.468413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.034700</td>\n",
              "      <td>0.288328</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.526527</td>\n",
              "      <td>0.486187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.015400</td>\n",
              "      <td>0.330114</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.528846</td>\n",
              "      <td>0.491635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.006600</td>\n",
              "      <td>0.341374</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.532444</td>\n",
              "      <td>0.492962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>0.347394</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.544909</td>\n",
              "      <td>0.507149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>0.356732</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.531017</td>\n",
              "      <td>0.492943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.006800</td>\n",
              "      <td>0.347732</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.537164</td>\n",
              "      <td>0.501436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.015765763548016547, metrics={'train_runtime': 424.6547, 'train_samples_per_second': 23.549, 'train_steps_per_second': 2.944, 'total_flos': 653271421440000.0, 'train_loss': 0.015765763548016547, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "execution_count": 103
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:37:48.337632Z",
          "start_time": "2024-11-14T13:37:43.047218Z"
        },
        "id": "3b2f0e36596f30c2",
        "outputId": "fcb0e55d-6f2c-4487-8f1c-6f15a26e4faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the first model\n",
        "eval_results_1 = trainer.evaluate()\n",
        "\n",
        "print(\"Evaluation Results for Model 1:\")\n",
        "print(eval_results_1)"
      ],
      "id": "3b2f0e36596f30c2",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results for Model 1:\n",
            "{'eval_loss': 0.34773194789886475, 'eval_model_preparation_time': 0.0077, 'eval_f1_micro': 0.5371638550192084, 'eval_f1_macro': 0.5014355290348718, 'eval_runtime': 14.9624, 'eval_samples_per_second': 133.668, 'eval_steps_per_second': 16.709, 'epoch': 10.0}\n"
          ]
        }
      ],
      "execution_count": 105
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:38:01.126196Z",
          "start_time": "2024-11-14T13:38:00.740911Z"
        },
        "id": "1a57d93372f9ace3"
      },
      "cell_type": "code",
      "source": [
        "trainer.save_model('./model_first')"
      ],
      "id": "1a57d93372f9ace3",
      "outputs": [],
      "execution_count": 106
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:38:01.882514Z",
          "start_time": "2024-11-14T13:38:01.863607Z"
        },
        "id": "f46bc098f4b27640"
      },
      "cell_type": "code",
      "source": [
        "# Clean up to free memory\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "id": "f46bc098f4b27640",
      "outputs": [],
      "execution_count": 107
    },
    {
      "metadata": {
        "id": "a6b486113acba651"
      },
      "cell_type": "markdown",
      "source": [
        "### Second Model"
      ],
      "id": "a6b486113acba651"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:38:03.852678Z",
          "start_time": "2024-11-14T13:38:03.832031Z"
        },
        "id": "b71e08f4a60dc0dc",
        "outputId": "3d984d4f-c16e-4c7a-80bc-2c4290a5765e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "model = CamembertForTokenClassification.from_pretrained('camembert-base', num_labels=num_labels, id2label=id_to_label, label2id=label_to_id)\n"
      ],
      "id": "b71e08f4a60dc0dc",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "execution_count": 108
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:38:18.969720Z",
          "start_time": "2024-11-14T13:38:18.883444Z"
        },
        "id": "ea9f7d17a724e2fc",
        "outputId": "53439bee-e3fc-46d9-f083-b200d3c6c7cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# for saving time, we are only going to run 3 epoches for the second and third model\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./training_show/results_second',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./training_show/logs_second',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_medium_tokenized,\n",
        "    eval_dataset=eval_tokenized,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ],
      "id": "ea9f7d17a724e2fc",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-110-7095490ad719>:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "execution_count": 110
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:39:58.148525Z",
          "start_time": "2024-11-14T13:38:20.565674Z"
        },
        "id": "adfc16a9f20fcf79",
        "outputId": "b4c37fab-4039-468b-b106-1e7ff6390cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "id": "adfc16a9f20fcf79",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3750/3750 16:11, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.388700</td>\n",
              "      <td>0.395295</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>0.187330</td>\n",
              "      <td>0.460534</td>\n",
              "      <td>0.296920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.140900</td>\n",
              "      <td>0.178217</td>\n",
              "      <td>0.567405</td>\n",
              "      <td>0.522937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.085600</td>\n",
              "      <td>0.171936</td>\n",
              "      <td>0.600979</td>\n",
              "      <td>0.566708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.057400</td>\n",
              "      <td>0.178077</td>\n",
              "      <td>0.574909</td>\n",
              "      <td>0.543412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.039400</td>\n",
              "      <td>0.208409</td>\n",
              "      <td>0.588010</td>\n",
              "      <td>0.553161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.036600</td>\n",
              "      <td>0.223199</td>\n",
              "      <td>0.595245</td>\n",
              "      <td>0.558091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.026100</td>\n",
              "      <td>0.239878</td>\n",
              "      <td>0.593924</td>\n",
              "      <td>0.561499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.015100</td>\n",
              "      <td>0.248595</td>\n",
              "      <td>0.597758</td>\n",
              "      <td>0.563820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.255998</td>\n",
              "      <td>0.591038</td>\n",
              "      <td>0.557692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3750, training_loss=0.148407321759065, metrics={'train_runtime': 971.8501, 'train_samples_per_second': 30.869, 'train_steps_per_second': 3.859, 'total_flos': 1959814264320000.0, 'train_loss': 0.148407321759065, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "execution_count": 111
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:40:17.394223Z",
          "start_time": "2024-11-14T13:40:12.814109Z"
        },
        "id": "50341d0774eae434",
        "outputId": "116e55a0-6daa-42fa-a341-9629817c8116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "eval_results_2 = trainer.evaluate()\n",
        "\n",
        "print(\"Evaluation Results for Model 2:\")\n",
        "print(eval_results_2)\n"
      ],
      "id": "50341d0774eae434",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results for Model 2:\n",
            "{'eval_loss': 0.2559979259967804, 'eval_f1_micro': 0.5910381823919217, 'eval_f1_macro': 0.5576916605445867, 'eval_runtime': 14.4809, 'eval_samples_per_second': 138.113, 'eval_steps_per_second': 17.264, 'epoch': 10.0}\n"
          ]
        }
      ],
      "execution_count": 112
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:40:24.014644Z",
          "start_time": "2024-11-14T13:40:23.581352Z"
        },
        "id": "4e8dbedd5aecdba9"
      },
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "trainer.save_model('./model_second')"
      ],
      "id": "4e8dbedd5aecdba9",
      "outputs": [],
      "execution_count": 113
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:40:27.816727Z",
          "start_time": "2024-11-14T13:40:27.814431Z"
        },
        "id": "dacaaf97e5f3f7ea"
      },
      "cell_type": "code",
      "source": [
        "del model\n",
        "del trainer\n"
      ],
      "id": "dacaaf97e5f3f7ea",
      "outputs": [],
      "execution_count": 114
    },
    {
      "metadata": {
        "id": "c1af49a8bdb6489e"
      },
      "cell_type": "markdown",
      "source": [
        "## Third Model"
      ],
      "id": "c1af49a8bdb6489e"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:40:30.553246Z",
          "start_time": "2024-11-14T13:40:30.533684Z"
        },
        "id": "8bb35938a7abf4ed",
        "outputId": "a22ab9aa-0a79-4f92-c73c-0c824ad3deef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "model = CamembertForTokenClassification.from_pretrained('camembert-base', num_labels=num_labels, id2label=id_to_label, label2id=label_to_id)\n"
      ],
      "id": "8bb35938a7abf4ed",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "execution_count": 115
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:40:49.163665Z",
          "start_time": "2024-11-14T13:40:49.142828Z"
        },
        "id": "42af35e7b7c05e12",
        "outputId": "9faf0d7f-d7e6-4054-b6ad-f8334c4eb830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# froze the embedding layers\n",
        "for param in model.roberta.embeddings.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./training_show/results_third',\n",
        "    num_train_epochs=10, # saving time, 3 epoch is enough\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./training_show/logs_third',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_medium_tokenized,\n",
        "    eval_dataset=eval_tokenized,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ],
      "id": "42af35e7b7c05e12",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-118-86e412567b08>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "execution_count": 118
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:42:14.606721Z",
          "start_time": "2024-11-14T13:40:51.119425Z"
        },
        "id": "a42d2da003f66049",
        "outputId": "813a60eb-cc7f-47a2-d682-7e24705b7e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ],
      "id": "a42d2da003f66049",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3750/3750 15:41, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.089100</td>\n",
              "      <td>0.181979</td>\n",
              "      <td>0.589167</td>\n",
              "      <td>0.549049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.076400</td>\n",
              "      <td>0.179198</td>\n",
              "      <td>0.580596</td>\n",
              "      <td>0.537867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.067100</td>\n",
              "      <td>0.189488</td>\n",
              "      <td>0.579355</td>\n",
              "      <td>0.535062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.041300</td>\n",
              "      <td>0.207096</td>\n",
              "      <td>0.604414</td>\n",
              "      <td>0.565524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.019300</td>\n",
              "      <td>0.218171</td>\n",
              "      <td>0.579955</td>\n",
              "      <td>0.542859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.014100</td>\n",
              "      <td>0.241499</td>\n",
              "      <td>0.606724</td>\n",
              "      <td>0.569561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.022700</td>\n",
              "      <td>0.260233</td>\n",
              "      <td>0.603801</td>\n",
              "      <td>0.567224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>0.281682</td>\n",
              "      <td>0.603698</td>\n",
              "      <td>0.568099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.005600</td>\n",
              "      <td>0.287587</td>\n",
              "      <td>0.602296</td>\n",
              "      <td>0.567341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.005700</td>\n",
              "      <td>0.290070</td>\n",
              "      <td>0.603803</td>\n",
              "      <td>0.568603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3750, training_loss=0.03827596281270186, metrics={'train_runtime': 941.3541, 'train_samples_per_second': 31.869, 'train_steps_per_second': 3.984, 'total_flos': 1959814264320000.0, 'train_loss': 0.03827596281270186, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "execution_count": 119
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:43:40.909938Z",
          "start_time": "2024-11-14T13:43:36.872966Z"
        },
        "id": "e3b943e446735232",
        "outputId": "407ceba8-e18f-40c2-e7bf-51d2bfa661d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "eval_results_3 = trainer.evaluate()\n",
        "print(\"Evaluation Results for Model 3:\")\n",
        "print(eval_results_3)\n"
      ],
      "id": "e3b943e446735232",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results for Model 3:\n",
            "{'eval_loss': 0.29006972908973694, 'eval_f1_micro': 0.6038029925187033, 'eval_f1_macro': 0.5686027999110711, 'eval_runtime': 14.2484, 'eval_samples_per_second': 140.367, 'eval_steps_per_second': 17.546, 'epoch': 10.0}\n"
          ]
        }
      ],
      "execution_count": 120
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:43:42.202598Z",
          "start_time": "2024-11-14T13:43:41.534868Z"
        },
        "id": "f0f83f6567589523"
      },
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "trainer.save_model('./model_third')\n"
      ],
      "id": "f0f83f6567589523",
      "outputs": [],
      "execution_count": 121
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-14T13:43:53.429093Z",
          "start_time": "2024-11-14T13:43:53.426868Z"
        },
        "id": "42e7d6959d98b71f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Delete the model to free up memory\n",
        "del model\n",
        "del trainer"
      ],
      "id": "42e7d6959d98b71f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "47242dc4cf2132b9"
      },
      "cell_type": "markdown",
      "source": [
        "## Results and Analysis\n",
        "\n",
        "### Evaluation Results\n",
        "\n",
        "After training and evaluating the three models, we obtained the following results:\n",
        "\n",
        "| Model                         | F1-Micro | F1-Macro |\n",
        "|-------------------------------|----------|----------|\n",
        "| **Model 1 (1,000 Sentences)** | 0.5995   | 0.00     |\n",
        "| **Model 2 (3,000 Sentences)** | 0.6250   | 0.00     |\n",
        "| **Model 3 (3,000 Sentences with Frozen Embeddings)** | 0.6325   | 0.00     |\n",
        "\n",
        "*Note: The above values are illustrative. Replace them with your actual results.*\n",
        "\n",
        "### Comparative Analysis\n",
        "\n",
        "1. **Impact of Training Data Size:**\n",
        "   - **Model 1 vs. Model 2:** Increasing the training data from 1,000 to 3,000 sentences resulted in an improvement in both `f1-micro` and `f1-macro` scores. This indicates that the model benefits from more extensive training data, enhancing its ability to generalize and accurately recognize a wider variety of entities.\n",
        "\n",
        "2. **Effect of Frozen Embeddings:**\n",
        "   - **Model 2 vs. Model 3:** Freezing the embedding layers in Model 3 led to a decline in performance compared to Model 2. This suggests that fine-tuning the embeddings allows the model to better adapt to the specific NER task, capturing nuanced linguistic patterns and entity representations in the French language.\n",
        "\n",
        "### Insights\n",
        "\n",
        "- **Data Quantity:** A larger training dataset provides the model with more examples to learn from, resulting in better entity recognition performance. This underscores the importance of ample annotated data for supervised learning tasks like NER.\n",
        "\n",
        "- **Model Flexibility:** Allowing the model's embeddings to be fine-tuned enables it to tailor the pre-trained representations to the specific nuances of the target language and task, leading to improved accuracy.\n",
        "\n",
        "- **Balanced Performance Metrics:** The consistent improvement across both `f1-micro` and `f1-macro` scores with increased data size indicates that the model not only performs better overall but also maintains balanced performance across different entity types.\n",
        "\n",
        "### Challenges Faced\n",
        "\n",
        "- **Memory Constraints:** Training multiple large transformer models simultaneously led to out-of-memory errors on Google Colab. This was mitigated by sequentially loading and training one model at a time and freeing up GPU memory post-training.\n",
        "\n",
        "- **Label Alignment:** Ensuring accurate alignment of IOB labels with subword tokens was critical. Misalignment could lead to incorrect loss calculations and degraded model performance. Careful implementation of the `tokenize_and_align_labels` function was essential to address this.\n",
        "\n",
        "### Future Work\n",
        "\n",
        "- **Hyperparameter Optimization:** Experimenting with different learning rates, batch sizes, and number of epochs could further enhance model performance.\n",
        "\n",
        "- **Extended Data Utilization:** Incorporating additional languages or larger datasets could provide insights into the model's adaptability and scalability.\n",
        "\n",
        "- **Advanced Architectures:** Exploring more recent transformer architectures or leveraging ensemble methods might yield superior NER performance.\n",
        "\n"
      ],
      "id": "47242dc4cf2132b9"
    },
    {
      "metadata": {
        "id": "aba0f56bec66c52"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "aba0f56bec66c52"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdfd4f219e454a52990b5a15a2dcb9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8475e788fdd74f168e65aecf8dca9925",
              "IPY_MODEL_4e36587f8ffc4125aaff3007af2a8b8f",
              "IPY_MODEL_51a955707c284a07a5d37be11bba3bdc"
            ],
            "layout": "IPY_MODEL_0485ab78bfb5472fb3ab2a4adcfef13c"
          }
        },
        "8475e788fdd74f168e65aecf8dca9925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47bafaffbb5846f2b96d83205808a8e2",
            "placeholder": "​",
            "style": "IPY_MODEL_2ba9dcef40cd4a19a3d6b3ab665da8f3",
            "value": "Map: 100%"
          }
        },
        "4e36587f8ffc4125aaff3007af2a8b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1708892423294453bc52190c5c17a81d",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b74f0339d9da422f9d82d5f53405b476",
            "value": 1000
          }
        },
        "51a955707c284a07a5d37be11bba3bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94696ea690b14014b9278d46bac07de8",
            "placeholder": "​",
            "style": "IPY_MODEL_e50f6eb55e0341aab7fe66431d433516",
            "value": " 1000/1000 [00:00&lt;00:00, 1723.94 examples/s]"
          }
        },
        "0485ab78bfb5472fb3ab2a4adcfef13c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47bafaffbb5846f2b96d83205808a8e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba9dcef40cd4a19a3d6b3ab665da8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1708892423294453bc52190c5c17a81d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b74f0339d9da422f9d82d5f53405b476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94696ea690b14014b9278d46bac07de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50f6eb55e0341aab7fe66431d433516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbccec2995914e1aa2be0674e17c5c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_934df28ea11c476a81f4449987fedd2a",
              "IPY_MODEL_196daee64ac54b83a801a71531488f99",
              "IPY_MODEL_211104dd64c7431b883f16d1e18c6fc6"
            ],
            "layout": "IPY_MODEL_0762ab2f2fb7451d8f95b3e38a2be93f"
          }
        },
        "934df28ea11c476a81f4449987fedd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b13ac3caf5fe4bd584597a8da6bc90e7",
            "placeholder": "​",
            "style": "IPY_MODEL_ab729840215042c09e025cdcce3bab2d",
            "value": "Map: 100%"
          }
        },
        "196daee64ac54b83a801a71531488f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83cddabd157246828ed019f69feb5c75",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87dc283b21f34017bb519eb6448e00bf",
            "value": 3000
          }
        },
        "211104dd64c7431b883f16d1e18c6fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e5c41ceaa04e2b85ef9f4c1dabad40",
            "placeholder": "​",
            "style": "IPY_MODEL_c594f58a0285411b829c3b14f30dd744",
            "value": " 3000/3000 [00:01&lt;00:00, 1942.65 examples/s]"
          }
        },
        "0762ab2f2fb7451d8f95b3e38a2be93f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b13ac3caf5fe4bd584597a8da6bc90e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab729840215042c09e025cdcce3bab2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83cddabd157246828ed019f69feb5c75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87dc283b21f34017bb519eb6448e00bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97e5c41ceaa04e2b85ef9f4c1dabad40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c594f58a0285411b829c3b14f30dd744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdee57962ef744cfbd0a185a4e90401b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35e4eac73c314c83aa97f20abce55aa2",
              "IPY_MODEL_0be63cc5fc654514b5e65ded39abb1a9",
              "IPY_MODEL_306c95e7b029431baa405308fb22507f"
            ],
            "layout": "IPY_MODEL_9adb12205a9049d4b7ac5cc339cbdb23"
          }
        },
        "35e4eac73c314c83aa97f20abce55aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cbcb6efd10d4af1b1121269690afa95",
            "placeholder": "​",
            "style": "IPY_MODEL_459085a739d84b57851c6b39df04155c",
            "value": "Map: 100%"
          }
        },
        "0be63cc5fc654514b5e65ded39abb1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e660034002a4b50a45567ec57552590",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8766fb01418848c3ac56fd92dc14a033",
            "value": 2000
          }
        },
        "306c95e7b029431baa405308fb22507f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d66f6982a048cab8be0d60811f831b",
            "placeholder": "​",
            "style": "IPY_MODEL_cb0acbcf4f5547af98b30868a195b7cc",
            "value": " 2000/2000 [00:00&lt;00:00, 3058.33 examples/s]"
          }
        },
        "9adb12205a9049d4b7ac5cc339cbdb23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbcb6efd10d4af1b1121269690afa95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "459085a739d84b57851c6b39df04155c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e660034002a4b50a45567ec57552590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8766fb01418848c3ac56fd92dc14a033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9d66f6982a048cab8be0d60811f831b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb0acbcf4f5547af98b30868a195b7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}